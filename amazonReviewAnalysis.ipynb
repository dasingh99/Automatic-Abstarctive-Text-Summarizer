{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4413,"status":"ok","timestamp":1669645843008,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"wVJ1awYvSEpC","outputId":"158deff5-ff1c-44ab-e5f7-a7eb0e12844e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450248,"status":"ok","timestamp":1669646293252,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"mOsdL39XTtL5","outputId":"8e02f1ba-7ccd-4d18-c8d1-77830e068c4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> d\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> all\n"]},{"output_type":"stream","name":"stderr","text":["    Downloading collection 'all'\n","       | \n","       | Downloading package abc to /root/nltk_data...\n","       |   Unzipping corpora/abc.zip.\n","       | Downloading package alpino to /root/nltk_data...\n","       |   Unzipping corpora/alpino.zip.\n","       | Downloading package averaged_perceptron_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","       | Downloading package averaged_perceptron_tagger_ru to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n","       | Downloading package basque_grammars to /root/nltk_data...\n","       |   Unzipping grammars/basque_grammars.zip.\n","       | Downloading package biocreative_ppi to /root/nltk_data...\n","       |   Unzipping corpora/biocreative_ppi.zip.\n","       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n","       |   Unzipping models/bllip_wsj_no_aux.zip.\n","       | Downloading package book_grammars to /root/nltk_data...\n","       |   Unzipping grammars/book_grammars.zip.\n","       | Downloading package brown to /root/nltk_data...\n","       |   Unzipping corpora/brown.zip.\n","       | Downloading package brown_tei to /root/nltk_data...\n","       |   Unzipping corpora/brown_tei.zip.\n","       | Downloading package cess_cat to /root/nltk_data...\n","       |   Unzipping corpora/cess_cat.zip.\n","       | Downloading package cess_esp to /root/nltk_data...\n","       |   Unzipping corpora/cess_esp.zip.\n","       | Downloading package chat80 to /root/nltk_data...\n","       |   Unzipping corpora/chat80.zip.\n","       | Downloading package city_database to /root/nltk_data...\n","       |   Unzipping corpora/city_database.zip.\n","       | Downloading package cmudict to /root/nltk_data...\n","       |   Unzipping corpora/cmudict.zip.\n","       | Downloading package comparative_sentences to\n","       |     /root/nltk_data...\n","       |   Unzipping corpora/comparative_sentences.zip.\n","       | Downloading package comtrans to /root/nltk_data...\n","       | Downloading package conll2000 to /root/nltk_data...\n","       |   Unzipping corpora/conll2000.zip.\n","       | Downloading package conll2002 to /root/nltk_data...\n","       |   Unzipping corpora/conll2002.zip.\n","       | Downloading package conll2007 to /root/nltk_data...\n","       | Downloading package crubadan to /root/nltk_data...\n","       |   Unzipping corpora/crubadan.zip.\n","       | Downloading package dependency_treebank to /root/nltk_data...\n","       |   Unzipping corpora/dependency_treebank.zip.\n","       | Downloading package dolch to /root/nltk_data...\n","       |   Unzipping corpora/dolch.zip.\n","       | Downloading package europarl_raw to /root/nltk_data...\n","       |   Unzipping corpora/europarl_raw.zip.\n","       | Downloading package extended_omw to /root/nltk_data...\n","       | Downloading package floresta to /root/nltk_data...\n","       |   Unzipping corpora/floresta.zip.\n","       | Downloading package framenet_v15 to /root/nltk_data...\n","       |   Unzipping corpora/framenet_v15.zip.\n","       | Downloading package framenet_v17 to /root/nltk_data...\n","       |   Unzipping corpora/framenet_v17.zip.\n","       | Downloading package gazetteers to /root/nltk_data...\n","       |   Unzipping corpora/gazetteers.zip.\n","       | Downloading package genesis to /root/nltk_data...\n","       |   Unzipping corpora/genesis.zip.\n","       | Downloading package gutenberg to /root/nltk_data...\n","       |   Unzipping corpora/gutenberg.zip.\n","       | Downloading package ieer to /root/nltk_data...\n","       |   Unzipping corpora/ieer.zip.\n","       | Downloading package inaugural to /root/nltk_data...\n","       |   Unzipping corpora/inaugural.zip.\n","       | Downloading package indian to /root/nltk_data...\n","       |   Unzipping corpora/indian.zip.\n","       | Downloading package jeita to /root/nltk_data...\n","       | Downloading package kimmo to /root/nltk_data...\n","       |   Unzipping corpora/kimmo.zip.\n","       | Downloading package knbc to /root/nltk_data...\n","       | Downloading package large_grammars to /root/nltk_data...\n","       |   Unzipping grammars/large_grammars.zip.\n","       | Downloading package lin_thesaurus to /root/nltk_data...\n","       |   Unzipping corpora/lin_thesaurus.zip.\n","       | Downloading package mac_morpho to /root/nltk_data...\n","       |   Unzipping corpora/mac_morpho.zip.\n","       | Downloading package machado to /root/nltk_data...\n","       | Downloading package masc_tagged to /root/nltk_data...\n","       | Downloading package maxent_ne_chunker to /root/nltk_data...\n","       |   Unzipping chunkers/maxent_ne_chunker.zip.\n","       | Downloading package maxent_treebank_pos_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","       | Downloading package moses_sample to /root/nltk_data...\n","       |   Unzipping models/moses_sample.zip.\n","       | Downloading package movie_reviews to /root/nltk_data...\n","       |   Unzipping corpora/movie_reviews.zip.\n","       | Downloading package mte_teip5 to /root/nltk_data...\n","       |   Unzipping corpora/mte_teip5.zip.\n","       | Downloading package mwa_ppdb to /root/nltk_data...\n","       |   Unzipping misc/mwa_ppdb.zip.\n","       | Downloading package names to /root/nltk_data...\n","       |   Unzipping corpora/names.zip.\n","       | Downloading package nombank.1.0 to /root/nltk_data...\n","       | Downloading package nonbreaking_prefixes to\n","       |     /root/nltk_data...\n","       |   Unzipping corpora/nonbreaking_prefixes.zip.\n","       | Downloading package nps_chat to /root/nltk_data...\n","       |   Unzipping corpora/nps_chat.zip.\n","       | Downloading package omw to /root/nltk_data...\n","       | Downloading package omw-1.4 to /root/nltk_data...\n","       | Downloading package opinion_lexicon to /root/nltk_data...\n","       |   Unzipping corpora/opinion_lexicon.zip.\n","       | Downloading package panlex_swadesh to /root/nltk_data...\n","       | Downloading package paradigms to /root/nltk_data...\n","       |   Unzipping corpora/paradigms.zip.\n","       | Downloading package pe08 to /root/nltk_data...\n","       |   Unzipping corpora/pe08.zip.\n","       | Downloading package perluniprops to /root/nltk_data...\n","       |   Unzipping misc/perluniprops.zip.\n","       | Downloading package pil to /root/nltk_data...\n","       |   Unzipping corpora/pil.zip.\n","       | Downloading package pl196x to /root/nltk_data...\n","       |   Unzipping corpora/pl196x.zip.\n","       | Downloading package porter_test to /root/nltk_data...\n","       |   Unzipping stemmers/porter_test.zip.\n","       | Downloading package ppattach to /root/nltk_data...\n","       |   Unzipping corpora/ppattach.zip.\n","       | Downloading package problem_reports to /root/nltk_data...\n","       |   Unzipping corpora/problem_reports.zip.\n","       | Downloading package product_reviews_1 to /root/nltk_data...\n","       |   Unzipping corpora/product_reviews_1.zip.\n","       | Downloading package product_reviews_2 to /root/nltk_data...\n","       |   Unzipping corpora/product_reviews_2.zip.\n","       | Downloading package propbank to /root/nltk_data...\n","       | Downloading package pros_cons to /root/nltk_data...\n","       |   Unzipping corpora/pros_cons.zip.\n","       | Downloading package ptb to /root/nltk_data...\n","       |   Unzipping corpora/ptb.zip.\n","       | Downloading package punkt to /root/nltk_data...\n","       |   Unzipping tokenizers/punkt.zip.\n","       | Downloading package qc to /root/nltk_data...\n","       |   Unzipping corpora/qc.zip.\n","       | Downloading package reuters to /root/nltk_data...\n","       | Downloading package rslp to /root/nltk_data...\n","       |   Unzipping stemmers/rslp.zip.\n","       | Downloading package rte to /root/nltk_data...\n","       |   Unzipping corpora/rte.zip.\n","       | Downloading package sample_grammars to /root/nltk_data...\n","       |   Unzipping grammars/sample_grammars.zip.\n","       | Downloading package semcor to /root/nltk_data...\n","       | Downloading package senseval to /root/nltk_data...\n","       |   Unzipping corpora/senseval.zip.\n","       | Downloading package sentence_polarity to /root/nltk_data...\n","       |   Unzipping corpora/sentence_polarity.zip.\n","       | Downloading package sentiwordnet to /root/nltk_data...\n","       |   Unzipping corpora/sentiwordnet.zip.\n","       | Downloading package shakespeare to /root/nltk_data...\n","       |   Unzipping corpora/shakespeare.zip.\n","       | Downloading package sinica_treebank to /root/nltk_data...\n","       |   Unzipping corpora/sinica_treebank.zip.\n","       | Downloading package smultron to /root/nltk_data...\n","       |   Unzipping corpora/smultron.zip.\n","       | Downloading package snowball_data to /root/nltk_data...\n","       | Downloading package spanish_grammars to /root/nltk_data...\n","       |   Unzipping grammars/spanish_grammars.zip.\n","       | Downloading package state_union to /root/nltk_data...\n","       |   Unzipping corpora/state_union.zip.\n","       | Downloading package stopwords to /root/nltk_data...\n","       |   Unzipping corpora/stopwords.zip.\n","       | Downloading package subjectivity to /root/nltk_data...\n","       |   Unzipping corpora/subjectivity.zip.\n","       | Downloading package swadesh to /root/nltk_data...\n","       |   Unzipping corpora/swadesh.zip.\n","       | Downloading package switchboard to /root/nltk_data...\n","       |   Unzipping corpora/switchboard.zip.\n","       | Downloading package tagsets to /root/nltk_data...\n","       |   Unzipping help/tagsets.zip.\n","       | Downloading package timit to /root/nltk_data...\n","       |   Unzipping corpora/timit.zip.\n","       | Downloading package toolbox to /root/nltk_data...\n","       |   Unzipping corpora/toolbox.zip.\n","       | Downloading package treebank to /root/nltk_data...\n","       |   Unzipping corpora/treebank.zip.\n","       | Downloading package twitter_samples to /root/nltk_data...\n","       |   Unzipping corpora/twitter_samples.zip.\n","       | Downloading package udhr to /root/nltk_data...\n","       |   Unzipping corpora/udhr.zip.\n","       | Downloading package udhr2 to /root/nltk_data...\n","       |   Unzipping corpora/udhr2.zip.\n","       | Downloading package unicode_samples to /root/nltk_data...\n","       |   Unzipping corpora/unicode_samples.zip.\n","       | Downloading package universal_tagset to /root/nltk_data...\n","       |   Unzipping taggers/universal_tagset.zip.\n","       | Downloading package universal_treebanks_v20 to\n","       |     /root/nltk_data...\n","       | Downloading package vader_lexicon to /root/nltk_data...\n","       | Downloading package verbnet to /root/nltk_data...\n","       |   Unzipping corpora/verbnet.zip.\n","       | Downloading package verbnet3 to /root/nltk_data...\n","       |   Unzipping corpora/verbnet3.zip.\n","       | Downloading package webtext to /root/nltk_data...\n","       |   Unzipping corpora/webtext.zip.\n","       | Downloading package wmt15_eval to /root/nltk_data...\n","       |   Unzipping models/wmt15_eval.zip.\n","       | Downloading package word2vec_sample to /root/nltk_data...\n","       |   Unzipping models/word2vec_sample.zip.\n","       | Downloading package wordnet to /root/nltk_data...\n","       | Downloading package wordnet2021 to /root/nltk_data...\n","       | Downloading package wordnet31 to /root/nltk_data...\n","       | Downloading package wordnet_ic to /root/nltk_data...\n","       |   Unzipping corpora/wordnet_ic.zip.\n","       | Downloading package words to /root/nltk_data...\n","       |   Unzipping corpora/words.zip.\n","       | Downloading package ycoe to /root/nltk_data...\n","       |   Unzipping corpora/ycoe.zip.\n","       | \n","     Done downloading collection all\n"]},{"name":"stdout","output_type":"stream","text":["\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> q\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["import nltk\n","nltk.download()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42601,"status":"ok","timestamp":1669646335828,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"aSbFslClc7jK","outputId":"c34cc3e6-7fd9-43b6-bd6c-719ee0ef0343"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==1.14.0\n","  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n","\u001b[K     |████████████████████████████████| 109.3 MB 45 kB/s \n","\u001b[?25hCollecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.19.6)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.38.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 32.9 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.1.0)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n","\u001b[K     |████████████████████████████████| 488 kB 18.6 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n","Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"]}],"source":["!pip install tensorflow==1.14.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3745,"status":"ok","timestamp":1669646339558,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"BQTXTPktNYZQ","outputId":"6a7a83b5-a879-4a1d-a2f4-5637f932c35e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorflow\n","Version: 1.14.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: absl-py, tensorflow-estimator, grpcio, wheel, keras-applications, six, protobuf, termcolor, numpy, google-pasta, wrapt, gast, tensorboard, keras-preprocessing, astor\n","Required-by: kapre\n"]}],"source":["pip show tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1994,"status":"ok","timestamp":1669646341548,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"78YTr4b9RL1z","outputId":"9c0cd16b-ddef-4ccb-af0e-251fe708a6e6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]},{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 1.14.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import re\n","from nltk.corpus import stopwords\n","import time\n","from tensorflow.python.layers.core import Dense\n","from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n","print('TensorFlow Version: {}'.format(tf.__version__))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29256,"status":"ok","timestamp":1669646370794,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"3MjOm2lHSbqR","outputId":"33493638-fd42-47fd-8473-b95dc5b87c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/My Drive/Amazon Fine Food Reviews.zip\n","replace /content/drive/My Drive/Reviews.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace /content/drive/My Drive/database.sqlite? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace /content/drive/My Drive/hashes.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"]}],"source":["!unzip \"/content/drive/My Drive/Amazon Fine Food Reviews.zip\" -d \"/content/drive/My Drive\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAtax0RXSmyZ"},"outputs":[],"source":["reviews = pd.read_csv(\"/content/drive/My Drive/Reviews.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669646377762,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"UMGeN3dkSj1Z","outputId":"e28bb2df-22b9-46e8-f48d-ab7421f07d28"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(568454, 10)"]},"metadata":{},"execution_count":9}],"source":["reviews.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1669646377763,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"lGohSNyeb0QU","outputId":"f2b7669a-2376-4800-d181-2ffb62c691ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["reviews['Text'][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1669646377764,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"i0rfklHjTRrr","outputId":"5309a33a-3e4c-4ba8-ca09-a635530205b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id   ProductId          UserId                      ProfileName  \\\n","0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n","1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n","2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n","3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n","4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n","\n","   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n","0                     1                       1      5  1303862400   \n","1                     0                       0      1  1346976000   \n","2                     1                       1      4  1219017600   \n","3                     3                       3      2  1307923200   \n","4                     0                       0      5  1350777600   \n","\n","                 Summary                                               Text  \n","0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n","1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n","2  \"Delight\" says it all  This is a confection that has been around a fe...  \n","3         Cough Medicine  If you are looking for the secret ingredient i...  \n","4            Great taffy  Great taffy at a great price.  There was a wid...  "],"text/html":["\n","  <div id=\"df-6b83f31b-c6f3-4f4e-945e-41464871d634\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>ProfileName</th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>B001E4KFG0</td>\n","      <td>A3SGXH7AUHU8GW</td>\n","      <td>delmartian</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1303862400</td>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>B00813GRG4</td>\n","      <td>A1D87F6ZCVE5NK</td>\n","      <td>dll pa</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1346976000</td>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>B000LQOCH0</td>\n","      <td>ABXLMWJIXXAIN</td>\n","      <td>Natalia Corres \"Natalia Corres\"</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1219017600</td>\n","      <td>\"Delight\" says it all</td>\n","      <td>This is a confection that has been around a fe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>B000UA0QIQ</td>\n","      <td>A395BORC6FGVXV</td>\n","      <td>Karl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1307923200</td>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>B006K2ZZ7K</td>\n","      <td>A1UQRSCLF8GW1T</td>\n","      <td>Michael D. Bigham \"M. Wassir\"</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1350777600</td>\n","      <td>Great taffy</td>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b83f31b-c6f3-4f4e-945e-41464871d634')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6b83f31b-c6f3-4f4e-945e-41464871d634 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6b83f31b-c6f3-4f4e-945e-41464871d634');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["reviews.head()\n"]},{"cell_type":"markdown","metadata":{"id":"eJPBlr-TIg6E"},"source":["Remove NULL data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1669646377764,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"WPNXZSVcTRwJ","outputId":"1b3b04bd-21bc-47f3-ed4c-21819eac413b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Id                         0\n","ProductId                  0\n","UserId                     0\n","ProfileName               16\n","HelpfulnessNumerator       0\n","HelpfulnessDenominator     0\n","Score                      0\n","Time                       0\n","Summary                   27\n","Text                       0\n","dtype: int64"]},"metadata":{},"execution_count":12}],"source":["reviews.isnull().sum()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1669646378451,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"QOi5VYOETRyQ","outputId":"0aa6165f-a84c-49a8-e842-0b3305d7a696"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}],"source":["reviews = reviews.dropna()\n","reviews = reviews.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator',\n","                        'Score','Time'], 1)\n","reviews = reviews.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669646378452,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"ugB-6tFyTXcB","outputId":"ba596390-075f-4340-e703-54993edfc199"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Summary                                               Text\n","0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n","1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n","2  \"Delight\" says it all  This is a confection that has been around a fe...\n","3         Cough Medicine  If you are looking for the secret ingredient i...\n","4            Great taffy  Great taffy at a great price.  There was a wid..."],"text/html":["\n","  <div id=\"df-6cfbc0e1-cf10-430d-be9f-4995253b6c8a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"Delight\" says it all</td>\n","      <td>This is a confection that has been around a fe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Great taffy</td>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cfbc0e1-cf10-430d-be9f-4995253b6c8a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6cfbc0e1-cf10-430d-be9f-4995253b6c8a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6cfbc0e1-cf10-430d-be9f-4995253b6c8a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["reviews.head()\n"]},{"cell_type":"markdown","metadata":{"id":"lQbMUbU9Iwnh"},"source":["Replacing contractions with long forms\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wN3TWTMhTXgg"},"outputs":[],"source":["contractions = { \n","\"ain't\": \"am not\",\n","\"aren't\": \"are not\",\n","\"can't\": \"cannot\",\n","\"can't've\": \"cannot have\",\n","\"'cause\": \"because\",\n","\"could've\": \"could have\",\n","\"couldn't\": \"could not\",\n","\"couldn't've\": \"could not have\",\n","\"didn't\": \"did not\",\n","\"doesn't\": \"does not\",\n","\"don't\": \"do not\",\n","\"hadn't\": \"had not\",\n","\"hadn't've\": \"had not have\",\n","\"hasn't\": \"has not\",\n","\"haven't\": \"have not\",\n","\"he'd\": \"he would\",\n","\"he'd've\": \"he would have\",\n","\"he'll\": \"he will\",\n","\"he's\": \"he is\",\n","\"how'd\": \"how did\",\n","\"how'll\": \"how will\",\n","\"how's\": \"how is\",\n","\"i'd\": \"i would\",\n","\"i'll\": \"i will\",\n","\"i'm\": \"i am\",\n","\"i've\": \"i have\",\n","\"isn't\": \"is not\",\n","\"it'd\": \"it would\",\n","\"it'll\": \"it will\",\n","\"it's\": \"it is\",\n","\"let's\": \"let us\",\n","\"ma'am\": \"madam\",\n","\"mayn't\": \"may not\",\n","\"might've\": \"might have\",\n","\"mightn't\": \"might not\",\n","\"must've\": \"must have\",\n","\"mustn't\": \"must not\",\n","\"needn't\": \"need not\",\n","\"oughtn't\": \"ought not\",\n","\"shan't\": \"shall not\",\n","\"sha'n't\": \"shall not\",\n","\"she'd\": \"she would\",\n","\"she'll\": \"she will\",\n","\"she's\": \"she is\",\n","\"should've\": \"should have\",\n","\"shouldn't\": \"should not\",\n","\"that'd\": \"that would\",\n","\"that's\": \"that is\",\n","\"there'd\": \"there had\",\n","\"there's\": \"there is\",\n","\"they'd\": \"they would\",\n","\"they'll\": \"they will\",\n","\"they're\": \"they are\",\n","\"they've\": \"they have\",\n","\"wasn't\": \"was not\",\n","\"we'd\": \"we would\",\n","\"we'll\": \"we will\",\n","\"we're\": \"we are\",\n","\"we've\": \"we have\",\n","\"weren't\": \"were not\",\n","\"what'll\": \"what will\",\n","\"what're\": \"what are\",\n","\"what's\": \"what is\",\n","\"what've\": \"what have\",\n","\"where'd\": \"where did\",\n","\"where's\": \"where is\",\n","\"who'll\": \"who will\",\n","\"who's\": \"who is\",\n","\"won't\": \"will not\",\n","\"wouldn't\": \"would not\",\n","\"you'd\": \"you would\",\n","\"you'll\": \"you will\",\n","\"you're\": \"you are\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgWQn9gtTj6p"},"outputs":[],"source":["def clean_text(text, remove_stopwords = True):\n","    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n","    \n","    # Convert words to lower case\n","    text = text.lower()\n","    \n","    # Replace contractions with their longer forms \n","    if True:\n","        text = text.split()\n","        new_text = []\n","        for word in text:\n","            if word in contractions:\n","                new_text.append(contractions[word])\n","            else:\n","                new_text.append(word)\n","        text = \" \".join(new_text)\n","    \n","    # Format words and remove unwanted characters\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text) \n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    \n","    # Optionally, remove stop words\n","    if remove_stopwords:\n","        text = text.split()\n","        stops = set(stopwords.words(\"english\"))\n","        text = [w for w in text if not w in stops]\n","        text = \" \".join(text)\n","\n","    return text"]},{"cell_type":"markdown","metadata":{"id":"AxNXquXTI68j"},"source":["Remove unwanted words\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120049,"status":"ok","timestamp":1669646498496,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"_byAuXe2TXjA","outputId":"c572b53f-f857-41a9-90d6-483c0e24af5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Summaries are complete.\n","Texts are complete.\n"]}],"source":["# Clean the summaries and texts\n","clean_summaries = []\n","for summary in reviews.Summary:\n","    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n","print(\"Summaries are complete.\")\n","\n","clean_texts = []\n","for text in reviews.Text:\n","    clean_texts.append(clean_text(text))\n","print(\"Texts are complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669646498496,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"K6fxqNTtTXnb","outputId":"73b2395f-7cbb-4cb3-8ca0-1610b6a90a8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Clean Review # 1\n","good quality dog food\n","bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n","\n","Clean Review # 2\n","not as advertised\n","product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n","\n","Clean Review # 3\n"," delight  says it all\n","confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n","\n","Clean Review # 4\n","cough medicine\n","looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal\n","\n","Clean Review # 5\n","great taffy\n","great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n","\n"]}],"source":["# Inspect the cleaned summaries and texts to ensure they have been cleaned well\n","for i in range(5):\n","    print(\"Clean Review #\",i+1)\n","    print(clean_summaries[i])\n","    print(clean_texts[i])\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"m6BlQaNzI_lj"},"source":["Count word frequency\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AatODxTAUJwZ"},"outputs":[],"source":["def count_words(count_dict, text):\n","    '''Count the number of occurrences of each word in a set of text'''\n","    for sentence in text:\n","        for word in sentence.split():\n","            if word not in count_dict:\n","                count_dict[word] = 1\n","            else:\n","                count_dict[word] += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7900,"status":"ok","timestamp":1669646506393,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"bGX_CkM9UJyp","outputId":"378e0698-602e-486b-9267-f20067feef7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Size of Vocabulary: 132884\n"]}],"source":["word_counts = {}\n","\n","count_words(word_counts, clean_summaries)\n","count_words(word_counts, clean_texts)\n","            \n","print(\"Size of Vocabulary:\", len(word_counts))"]},{"cell_type":"markdown","metadata":{"id":"vHfOXcyYJFBQ"},"source":["Word Embedding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28379,"status":"ok","timestamp":1669646534769,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"4qboZzfOUJ1D","outputId":"9097670e-9e4a-4703-a0b6-3d88fe8bb900"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word embeddings: 417195\n"]}],"source":["embeddings_index = {}\n","with open('/content/drive/My Drive/numberbatch-en.txt', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split(' ')\n","        word = values[0]\n","        embedding = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = embedding\n","\n","print('Word embeddings:', len(embeddings_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1669646534770,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"h5qWeNhJUQaI","outputId":"69d447b1-6777-464a-97c1-6a0bcbf3c2c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words missing from CN: 3870\n","Percent of words that are missing from vocabulary: 2.91%\n"]}],"source":["missing_words = 0\n","threshold = 20\n","\n","for word, count in word_counts.items():\n","    if count > threshold:\n","        if word not in embeddings_index:\n","            missing_words += 1\n","            \n","missing_ratio = round(missing_words/len(word_counts),4)*100\n","            \n","print(\"Number of words missing from CN:\", missing_words)\n","print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1669646534770,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"mtvYnFJ2UJ28","outputId":"4eab0f69-d369-4e88-ab29-6e36d3911b23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of unique words: 132884\n","Number of words we will use: 59595\n","Percent of words we will use: 44.85%\n"]}],"source":["vocab_to_int = {} \n","\n","value = 0\n","for word, count in word_counts.items():\n","    if count >= threshold or word in embeddings_index:\n","        vocab_to_int[word] = value\n","        value += 1\n","\n","# Special tokens that will be added to our vocab\n","codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n","\n","# Add codes to vocab\n","for code in codes:\n","    vocab_to_int[code] = len(vocab_to_int)\n","\n","# Dictionary to convert integers to words\n","int_to_vocab = {}\n","for word, value in vocab_to_int.items():\n","    int_to_vocab[value] = word\n","\n","usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n","\n","print(\"Total number of unique words:\", len(word_counts))\n","print(\"Number of words we will use:\", len(vocab_to_int))\n","print(\"Percent of words we will use: {}%\".format(usage_ratio))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1669646534771,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"EJOB06j1WQF2","outputId":"f7d82937-fc9c-4431-c5fb-511c98c77802"},"outputs":[{"output_type":"stream","name":"stdout","text":["59595\n"]}],"source":["embedding_dim = 300\n","nb_words = len(vocab_to_int)\n","\n","# Create matrix with default values of zero\n","word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n","for word, i in vocab_to_int.items():\n","    if word in embeddings_index:\n","        word_embedding_matrix[i] = embeddings_index[word]\n","    else:\n","        # If word not in CN, create a random embedding for it\n","        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n","        embeddings_index[word] = new_embedding\n","        word_embedding_matrix[i] = new_embedding\n","\n","# Check if value matches len(vocab_to_int)\n","print(len(word_embedding_matrix))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LFwGBcYLWS0h"},"outputs":[],"source":["def convert_to_ints(text, word_count, unk_count, eos=False):\n","    '''Convert words in text to an integer.\n","       If word is not in vocab_to_int, use UNK's integer.\n","       Total the number of words and UNKs.\n","       Add EOS token to the end of texts'''\n","    ints = []\n","    for sentence in text:\n","        sentence_ints = []\n","        for word in sentence.split():\n","            word_count += 1\n","            if word in vocab_to_int:\n","                sentence_ints.append(vocab_to_int[word])\n","            else:\n","                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n","                unk_count += 1\n","        if eos:\n","            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n","        ints.append(sentence_ints)\n","    return ints, word_count, unk_count"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13332,"status":"ok","timestamp":1669646548091,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"-fnei7VeUJ45","outputId":"1c70cb44-6f26-47e6-d9d9-1da53bc0ab6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of words in headlines: 25679933\n","Total number of UNKs in headlines: 192245\n","Percent of words that are UNK: 0.75%\n"]}],"source":["word_count = 0\n","unk_count = 0\n","\n","int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n","int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count, eos=True)\n","\n","unk_percent = round(unk_count/word_count,4)*100\n","\n","print(\"Total number of words in headlines:\", word_count)\n","print(\"Total number of UNKs in headlines:\", unk_count)\n","print(\"Percent of words that are UNK: {}%\".format(unk_percent))"]},{"cell_type":"markdown","metadata":{"id":"rL8oWC4JJLOd"},"source":["Sort data by length of description"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkI8vFIXZSrD"},"outputs":[],"source":["\n","def create_lengths(text):\n","    '''Create a data frame of the sentence lengths from a text'''\n","    lengths = []\n","    for sentence in text:\n","        lengths.append(len(sentence))\n","    return pd.DataFrame(lengths, columns=['counts'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":904,"status":"ok","timestamp":1669646548985,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"aQEQM3LcZStQ","outputId":"3b5bb41c-2019-4111-cfdf-0b2a3b86ebca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Summaries:\n","              counts\n","count  568411.000000\n","mean        4.181624\n","std         2.657872\n","min         0.000000\n","25%         2.000000\n","50%         4.000000\n","75%         5.000000\n","max        48.000000\n","\n","Texts:\n","              counts\n","count  568411.000000\n","mean       41.996835\n","std        42.520873\n","min         1.000000\n","25%        18.000000\n","50%        29.000000\n","75%        50.000000\n","max      2085.000000\n"]}],"source":["\n","lengths_summaries = create_lengths(int_summaries)\n","lengths_texts = create_lengths(int_texts)\n","\n","print(\"Summaries:\")\n","print(lengths_summaries.describe())\n","print()\n","print(\"Texts:\")\n","print(lengths_texts.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1669646548986,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"f0H0sB4AZSvP","outputId":"93deedac-2cdb-44a3-ad27-459a6570b53b"},"outputs":[{"output_type":"stream","name":"stdout","text":["84.0\n","115.0\n","207.0\n"]}],"source":["print(np.percentile(lengths_texts.counts, 90))\n","print(np.percentile(lengths_texts.counts, 95))\n","print(np.percentile(lengths_texts.counts, 99))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669646548986,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"hL-xdNpMZSxd","outputId":"1461f958-d9ad-47f6-ed9b-929c696710b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["8.0\n","9.0\n","13.0\n"]}],"source":["print(np.percentile(lengths_summaries.counts, 90))\n","print(np.percentile(lengths_summaries.counts, 95))\n","print(np.percentile(lengths_summaries.counts, 99))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ne02X-9gZZ5A"},"outputs":[],"source":["def unk_counter(sentence):\n","    '''Counts the number of time UNK appears in a sentence.'''\n","    unk_count = 0\n","    for word in sentence:\n","        if word == vocab_to_int[\"<UNK>\"]:\n","            unk_count += 1\n","    return unk_count"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232870,"status":"ok","timestamp":1669646781853,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"9ArcDlHAZZ2Z","outputId":"bb99c33a-07a4-4627-fcfe-fc6579b274b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["425615\n","425615\n"]}],"source":["\n","sorted_summaries = []\n","sorted_texts = []\n","max_text_length = 84\n","max_summary_length = 13\n","min_length = 2\n","unk_text_limit = 1\n","unk_summary_limit = 0\n","\n","for length in range(min(lengths_texts.counts), max_text_length): \n","    for count, words in enumerate(int_summaries):\n","        if (len(int_summaries[count]) >= min_length and\n","            len(int_summaries[count]) <= max_summary_length and\n","            len(int_texts[count]) >= min_length and\n","            unk_counter(int_summaries[count]) <= unk_summary_limit and\n","            unk_counter(int_texts[count]) <= unk_text_limit and\n","            length == len(int_texts[count])\n","           ):\n","            sorted_summaries.append(int_summaries[count])\n","            sorted_texts.append(int_texts[count])\n","        \n","# Compare lengths to ensure they match\n","print(len(sorted_summaries))\n","print(len(sorted_texts))"]},{"cell_type":"markdown","metadata":{"id":"GqbMdlvDIZGZ"},"source":["Model Building\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qiytumB7IYsZ"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R5PiX_k7ZdTx"},"outputs":[],"source":["def model_inputs():\n","    '''Create palceholders for inputs to the model'''\n","    \n","    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n","    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n","    lr = tf.placeholder(tf.float32, name='learning_rate')\n","    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n","    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n","    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n","    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n","\n","    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_As8iGaZdWP"},"outputs":[],"source":["def process_encoding_input(target_data, vocab_to_int, batch_size):\n","    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n","    \n","    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n","    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n","\n","    return dec_input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilY9t0vgZdYz"},"outputs":[],"source":["def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n","    '''Create the encoding layer'''\n","    \n","    for layer in range(num_layers):\n","        with tf.variable_scope('encoder_{}'.format(layer)):\n","            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,\n","                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n","            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n","                                                    input_keep_prob = keep_prob)\n","\n","            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,\n","                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n","            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n","                                                    input_keep_prob = keep_prob)\n","\n","            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n","                                                                    cell_bw, \n","                                                                    rnn_inputs,\n","                                                                    sequence_length,\n","                                                                    dtype=tf.float32)\n","    # Join outputs since we are using a bidirectional RNN\n","    enc_output = tf.concat(enc_output,2)\n","    \n","    return enc_output, enc_state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrVrY4jSZrxb"},"outputs":[],"source":["def training_decoding_layer(dec_embed_input, summary_length, dec_cell, initial_state, output_layer, \n","                            vocab_size, max_summary_length):\n","    '''Create the training logits'''\n","    \n","    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n","                                                        sequence_length=summary_length,\n","                                                        time_major=False)\n","\n","    training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n","                                                       training_helper,\n","                                                       initial_state,\n","                                                       output_layer) \n","\n","    training_logits, _ ,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n","                                                              output_time_major=False,\n","                                                              impute_finished=True,\n","                                                              maximum_iterations= max_summary_length)\n","    return training_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaRWgg79Zulg"},"outputs":[],"source":["def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n","                             max_summary_length, batch_size):\n","    '''Create the inference logits'''\n","    \n","    start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n","    \n","    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n","                                                                start_tokens,\n","                                                                end_token)\n","                \n","    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n","                                                        inference_helper,\n","                                                        initial_state,\n","                                                        output_layer)\n","                \n","    inference_logits, _ ,_ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n","                                                               output_time_major=False,\n","                                                              impute_finished=True,\n","                                                              maximum_iterations= max_summary_length)\n","    \n","    return inference_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4121,"status":"ok","timestamp":1669646785969,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"_aGv4ASIIxbq","outputId":"092e015a-ce11-40b4-effe-c9bfd6881f56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.18.0\n"]}],"source":["!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLk4tgIbZwXt"},"outputs":[],"source":["def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, \n","                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):\n","    '''Create the decoding cell and attention for the training and inference decoding layers'''\n","    \n","    for layer in range(num_layers):\n","        with tf.variable_scope('decoder_{}'.format(layer)):\n","            lstm = tf.contrib.rnn.LSTMCell(rnn_size,\n","                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n","            dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n","                                                     input_keep_prob = keep_prob)\n","    \n","    output_layer = Dense(vocab_size,\n","                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n","    \n","    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n","                                                  enc_output,\n","                                                  text_length,\n","                                                  normalize=False,\n","                                                  name='BahdanauAttention')\n","\n","    dec_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell,\n","                                                          attn_mech,\n","                                                          rnn_size)\n","            \n","    initial_state = dec_cell.zero_state(batch_size=batch_size,dtype=tf.float32).clone(cell_state=enc_state[0])\n","\n","    with tf.variable_scope(\"decode\"):\n","        training_logits = training_decoding_layer(dec_embed_input, \n","                                                  summary_length, \n","                                                  dec_cell, \n","                                                  initial_state,\n","                                                  output_layer,\n","                                                  vocab_size, \n","                                                  max_summary_length)\n","    with tf.variable_scope(\"decode\", reuse=True):\n","        inference_logits = inference_decoding_layer(embeddings,  \n","                                                    vocab_to_int['<GO>'], \n","                                                    vocab_to_int['<EOS>'],\n","                                                    dec_cell, \n","                                                    initial_state, \n","                                                    output_layer,\n","                                                    max_summary_length,\n","                                                    batch_size)\n","\n","    return training_logits, inference_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySPdBBCBZ0Ow"},"outputs":[],"source":["def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, \n","                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n","    '''Use the previous functions to create the training and inference logits'''\n","    \n","    # Use Numberbatch's embeddings and the newly created ones as our embeddings\n","    embeddings = word_embedding_matrix\n","    \n","    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n","    enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n","    \n","    dec_input = process_encoding_input(target_data, vocab_to_int, batch_size)\n","    dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)\n","    \n","    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n","                                                        embeddings,\n","                                                        enc_output,\n","                                                        enc_state, \n","                                                        vocab_size, \n","                                                        text_length, \n","                                                        summary_length, \n","                                                        max_summary_length,\n","                                                        rnn_size, \n","                                                        vocab_to_int, \n","                                                        keep_prob, \n","                                                        batch_size,\n","                                                        num_layers)\n","    \n","    return training_logits, inference_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOyMymLCZ0GJ"},"outputs":[],"source":["def pad_sentence_batch(sentence_batch):\n","    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n","    max_sentence = max([len(sentence) for sentence in sentence_batch])\n","    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Py4PjFAYZ0IX"},"outputs":[],"source":["\n","def get_batches(summaries, texts, batch_size):\n","    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n","    for batch_i in range(0, len(texts)//batch_size):\n","        start_i = batch_i * batch_size\n","        summaries_batch = summaries[start_i:start_i + batch_size]\n","        texts_batch = texts[start_i:start_i + batch_size]\n","        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n","        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n","        \n","        # Need the lengths for the _lengths parameters\n","        pad_summaries_lengths = []\n","        for summary in pad_summaries_batch:\n","            pad_summaries_lengths.append(len(summary))\n","        \n","        pad_texts_lengths = []\n","        for text in pad_texts_batch:\n","            pad_texts_lengths.append(len(text))\n","        \n","        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxXeESKbZ0KY"},"outputs":[],"source":["\n","# Set the Hyperparameters\n","epochs = 5\n","batch_size = 64\n","rnn_size = 256\n","num_layers = 2\n","learning_rate = 0.005\n","keep_probability = 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6515,"status":"ok","timestamp":1669646792473,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"B9xLBoPtZ0Mn","outputId":"e098d464-73fe-4241-bb52-49745cfd458d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-35-9390cb26606a>:7: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-35-9390cb26606a>:20: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1613850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1613850>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1613850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1613850>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e14edc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e14edc90>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e50d4550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e50d4550>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e14edc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e14edc90>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e50d4550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e50d4550>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1338bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1338bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1338bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e1338bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4990>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4990>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>>: AttributeError: module 'gast' has no attribute 'Index'\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f69e0bfc5d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f69e139b710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e50d4710>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e0c026d0>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f69e129b910>>: AttributeError: module 'gast' has no attribute 'Index'\n","Graph is built.\n"]}],"source":["# Build the graph\n","train_graph = tf.Graph()\n","# Set the graph to default to ensure that it is ready for training\n","with train_graph.as_default():\n","    \n","    # Load the model inputs    \n","    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()\n","\n","    # Create the training and inference logits\n","    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n","                                                      targets, \n","                                                      keep_prob,   \n","                                                      text_length,\n","                                                      summary_length,\n","                                                      max_summary_length,\n","                                                      len(vocab_to_int)+1,\n","                                                      rnn_size, \n","                                                      num_layers, \n","                                                      vocab_to_int,\n","                                                      batch_size)\n","    \n","    # Create tensors for the training logits and inference logits\n","    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n","    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n","    \n","    # Create the weights for sequence_loss\n","    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n","\n","    with tf.name_scope(\"optimization\"):\n","        # Loss function\n","        cost = tf.contrib.seq2seq.sequence_loss(\n","            training_logits,\n","            targets,\n","            masks)\n","\n","        # Optimizer\n","        optimizer = tf.train.AdamOptimizer(learning_rate)\n","\n","        # Gradient Clipping\n","        gradients = optimizer.compute_gradients(cost)\n","        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n","        train_op = optimizer.apply_gradients(capped_gradients)\n","print(\"Graph is built.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1669646792474,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"},"user_tz":-330},"id":"MoXyeZrWaAYV","outputId":"013096ac-7691-4268-8627-f0354868b354"},"outputs":[{"output_type":"stream","name":"stdout","text":["The shortest text length: 25\n","The longest text length: 31\n"]}],"source":["# Subset the data for training\n","start = 200000\n","\n","end = start + 50000\n","sorted_summaries_short = sorted_summaries[start:end]\n","sorted_texts_short = sorted_texts[start:end]\n","print(\"The shortest text length:\", len(sorted_texts_short[0]))\n","print(\"The longest text length:\",len(sorted_texts_short[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MET-Zo7iaAao","executionInfo":{"status":"ok","timestamp":1669660687483,"user_tz":-330,"elapsed":10812455,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"}},"outputId":"6601e6fe-97f2-4f59-8f52-0324308f9abf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch   1/5 Batch   20/781 - Loss:  4.499, Seconds: 72.81\n","Epoch   1/5 Batch   40/781 - Loss:  2.870, Seconds: 72.87\n","Epoch   1/5 Batch   60/781 - Loss:  2.841, Seconds: 62.05\n","Epoch   1/5 Batch   80/781 - Loss:  2.723, Seconds: 78.89\n","Epoch   1/5 Batch  100/781 - Loss:  2.796, Seconds: 69.11\n","Epoch   1/5 Batch  120/781 - Loss:  2.687, Seconds: 67.93\n","Epoch   1/5 Batch  140/781 - Loss:  2.588, Seconds: 68.44\n","Epoch   1/5 Batch  160/781 - Loss:  2.587, Seconds: 78.47\n","Epoch   1/5 Batch  180/781 - Loss:  2.521, Seconds: 73.84\n","Epoch   1/5 Batch  200/781 - Loss:  2.610, Seconds: 64.01\n","Epoch   1/5 Batch  220/781 - Loss:  2.598, Seconds: 90.53\n","Epoch   1/5 Batch  240/781 - Loss:  2.529, Seconds: 54.12\n","Average loss for this update: 2.787\n","New Record!\n","Epoch   1/5 Batch  260/781 - Loss:  2.357, Seconds: 67.16\n","Epoch   1/5 Batch  280/781 - Loss:  2.233, Seconds: 76.93\n","Epoch   1/5 Batch  300/781 - Loss:  2.333, Seconds: 66.59\n","Epoch   1/5 Batch  320/781 - Loss:  2.409, Seconds: 66.75\n","Epoch   1/5 Batch  340/781 - Loss:  2.589, Seconds: 57.02\n","Epoch   1/5 Batch  360/781 - Loss:  2.367, Seconds: 77.36\n","Epoch   1/5 Batch  380/781 - Loss:  2.370, Seconds: 76.58\n","Epoch   1/5 Batch  400/781 - Loss:  2.164, Seconds: 77.49\n","Epoch   1/5 Batch  420/781 - Loss:  2.154, Seconds: 64.06\n","Epoch   1/5 Batch  440/781 - Loss:  2.144, Seconds: 67.13\n","Epoch   1/5 Batch  460/781 - Loss:  2.380, Seconds: 67.63\n","Epoch   1/5 Batch  480/781 - Loss:  2.383, Seconds: 62.29\n","Epoch   1/5 Batch  500/781 - Loss:  2.285, Seconds: 77.85\n","Average loss for this update: 2.315\n","New Record!\n","Epoch   1/5 Batch  520/781 - Loss:  2.257, Seconds: 76.57\n","Epoch   1/5 Batch  540/781 - Loss:  2.130, Seconds: 59.80\n","Epoch   1/5 Batch  560/781 - Loss:  2.091, Seconds: 65.16\n","Epoch   1/5 Batch  580/781 - Loss:  2.177, Seconds: 65.69\n","Epoch   1/5 Batch  600/781 - Loss:  2.255, Seconds: 61.38\n","Epoch   1/5 Batch  620/781 - Loss:  2.500, Seconds: 76.80\n","Epoch   1/5 Batch  640/781 - Loss:  2.311, Seconds: 82.67\n","Epoch   1/5 Batch  660/781 - Loss:  2.229, Seconds: 72.29\n","Epoch   1/5 Batch  680/781 - Loss:  2.074, Seconds: 65.33\n","Epoch   1/5 Batch  700/781 - Loss:  2.008, Seconds: 81.66\n","Epoch   1/5 Batch  720/781 - Loss:  2.079, Seconds: 72.59\n","Epoch   1/5 Batch  740/781 - Loss:  2.409, Seconds: 55.71\n","Epoch   1/5 Batch  760/781 - Loss:  2.303, Seconds: 60.99\n","Average loss for this update: 2.204\n","New Record!\n","Epoch   1/5 Batch  780/781 - Loss:  2.081, Seconds: 119.17\n","Epoch   2/5 Batch   20/781 - Loss:  2.222, Seconds: 71.83\n","Epoch   2/5 Batch   40/781 - Loss:  2.062, Seconds: 72.25\n","Epoch   2/5 Batch   60/781 - Loss:  2.074, Seconds: 92.49\n","Epoch   2/5 Batch   80/781 - Loss:  1.998, Seconds: 77.33\n","Epoch   2/5 Batch  100/781 - Loss:  2.072, Seconds: 67.88\n","Epoch   2/5 Batch  120/781 - Loss:  1.972, Seconds: 68.03\n","Epoch   2/5 Batch  140/781 - Loss:  1.883, Seconds: 67.60\n","Epoch   2/5 Batch  160/781 - Loss:  1.889, Seconds: 79.10\n","Epoch   2/5 Batch  180/781 - Loss:  1.908, Seconds: 73.07\n","Epoch   2/5 Batch  200/781 - Loss:  2.015, Seconds: 62.92\n","Epoch   2/5 Batch  220/781 - Loss:  2.013, Seconds: 68.74\n","Epoch   2/5 Batch  240/781 - Loss:  1.935, Seconds: 52.82\n","Average loss for this update: 1.988\n","New Record!\n","Epoch   2/5 Batch  260/781 - Loss:  1.797, Seconds: 68.97\n","Epoch   2/5 Batch  280/781 - Loss:  1.651, Seconds: 77.87\n","Epoch   2/5 Batch  300/781 - Loss:  1.765, Seconds: 68.14\n","Epoch   2/5 Batch  320/781 - Loss:  1.847, Seconds: 67.90\n","Epoch   2/5 Batch  340/781 - Loss:  2.115, Seconds: 58.89\n","Epoch   2/5 Batch  360/781 - Loss:  1.914, Seconds: 77.92\n","Epoch   2/5 Batch  380/781 - Loss:  1.878, Seconds: 79.74\n","Epoch   2/5 Batch  400/781 - Loss:  1.709, Seconds: 78.53\n","Epoch   2/5 Batch  420/781 - Loss:  1.669, Seconds: 63.29\n","Epoch   2/5 Batch  440/781 - Loss:  1.700, Seconds: 68.50\n","Epoch   2/5 Batch  460/781 - Loss:  1.903, Seconds: 68.13\n","Epoch   2/5 Batch  480/781 - Loss:  1.939, Seconds: 63.86\n","Epoch   2/5 Batch  500/781 - Loss:  1.833, Seconds: 78.33\n","Average loss for this update: 1.828\n","New Record!\n","Epoch   2/5 Batch  520/781 - Loss:  1.828, Seconds: 73.76\n","Epoch   2/5 Batch  540/781 - Loss:  1.679, Seconds: 58.45\n","Epoch   2/5 Batch  560/781 - Loss:  1.672, Seconds: 63.86\n","Epoch   2/5 Batch  580/781 - Loss:  1.744, Seconds: 64.09\n","Epoch   2/5 Batch  600/781 - Loss:  1.831, Seconds: 70.75\n","Epoch   2/5 Batch  620/781 - Loss:  2.068, Seconds: 75.23\n","Epoch   2/5 Batch  640/781 - Loss:  1.878, Seconds: 80.00\n","Epoch   2/5 Batch  660/781 - Loss:  1.824, Seconds: 69.45\n","Epoch   2/5 Batch  680/781 - Loss:  1.667, Seconds: 64.36\n","Epoch   2/5 Batch  700/781 - Loss:  1.643, Seconds: 80.76\n","Epoch   2/5 Batch  720/781 - Loss:  1.702, Seconds: 69.89\n","Epoch   2/5 Batch  740/781 - Loss:  2.052, Seconds: 54.49\n","Epoch   2/5 Batch  760/781 - Loss:  1.981, Seconds: 59.55\n","Average loss for this update: 1.808\n","New Record!\n","Epoch   2/5 Batch  780/781 - Loss:  1.772, Seconds: 79.06\n","Epoch   3/5 Batch   20/781 - Loss:  1.989, Seconds: 74.05\n","Epoch   3/5 Batch   40/781 - Loss:  1.818, Seconds: 72.97\n","Epoch   3/5 Batch   60/781 - Loss:  1.796, Seconds: 62.59\n","Epoch   3/5 Batch   80/781 - Loss:  1.724, Seconds: 77.74\n","Epoch   3/5 Batch  100/781 - Loss:  1.787, Seconds: 68.02\n","Epoch   3/5 Batch  120/781 - Loss:  1.662, Seconds: 67.02\n","Epoch   3/5 Batch  140/781 - Loss:  1.580, Seconds: 67.65\n","Epoch   3/5 Batch  160/781 - Loss:  1.603, Seconds: 78.36\n","Epoch   3/5 Batch  180/781 - Loss:  1.659, Seconds: 72.44\n","Epoch   3/5 Batch  200/781 - Loss:  1.731, Seconds: 63.46\n","Epoch   3/5 Batch  220/781 - Loss:  1.742, Seconds: 68.05\n","Epoch   3/5 Batch  240/781 - Loss:  1.632, Seconds: 53.23\n","Average loss for this update: 1.713\n","New Record!\n","Epoch   3/5 Batch  260/781 - Loss:  1.539, Seconds: 68.23\n","Epoch   3/5 Batch  280/781 - Loss:  1.409, Seconds: 79.03\n","Epoch   3/5 Batch  300/781 - Loss:  1.523, Seconds: 67.90\n","Epoch   3/5 Batch  320/781 - Loss:  1.590, Seconds: 67.65\n","Epoch   3/5 Batch  340/781 - Loss:  1.856, Seconds: 58.11\n","Epoch   3/5 Batch  360/781 - Loss:  1.678, Seconds: 78.35\n","Epoch   3/5 Batch  380/781 - Loss:  1.629, Seconds: 79.00\n","Epoch   3/5 Batch  400/781 - Loss:  1.466, Seconds: 79.03\n","Epoch   3/5 Batch  420/781 - Loss:  1.424, Seconds: 63.48\n","Epoch   3/5 Batch  440/781 - Loss:  1.473, Seconds: 69.25\n","Epoch   3/5 Batch  460/781 - Loss:  1.654, Seconds: 69.94\n","Epoch   3/5 Batch  480/781 - Loss:  1.703, Seconds: 64.08\n","Epoch   3/5 Batch  500/781 - Loss:  1.595, Seconds: 79.04\n","Average loss for this update: 1.586\n","New Record!\n","Epoch   3/5 Batch  520/781 - Loss:  1.612, Seconds: 73.80\n","Epoch   3/5 Batch  540/781 - Loss:  1.446, Seconds: 58.15\n","Epoch   3/5 Batch  560/781 - Loss:  1.449, Seconds: 63.19\n","Epoch   3/5 Batch  580/781 - Loss:  1.524, Seconds: 64.79\n","Epoch   3/5 Batch  600/781 - Loss:  1.608, Seconds: 59.10\n","Epoch   3/5 Batch  620/781 - Loss:  1.825, Seconds: 74.29\n","Epoch   3/5 Batch  640/781 - Loss:  1.632, Seconds: 79.42\n","Epoch   3/5 Batch  660/781 - Loss:  1.603, Seconds: 69.29\n","Epoch   3/5 Batch  680/781 - Loss:  1.439, Seconds: 64.43\n","Epoch   3/5 Batch  700/781 - Loss:  1.436, Seconds: 78.78\n","Epoch   3/5 Batch  720/781 - Loss:  1.507, Seconds: 69.97\n","Epoch   3/5 Batch  740/781 - Loss:  1.840, Seconds: 54.56\n","Epoch   3/5 Batch  760/781 - Loss:  1.786, Seconds: 59.73\n","Average loss for this update: 1.59\n","No Improvement.\n","Epoch   3/5 Batch  780/781 - Loss:  1.589, Seconds: 69.86\n","Epoch   4/5 Batch   20/781 - Loss:  1.843, Seconds: 71.16\n","Epoch   4/5 Batch   40/781 - Loss:  1.645, Seconds: 71.23\n","Epoch   4/5 Batch   60/781 - Loss:  1.625, Seconds: 62.40\n","Epoch   4/5 Batch   80/781 - Loss:  1.553, Seconds: 77.42\n","Epoch   4/5 Batch  100/781 - Loss:  1.605, Seconds: 67.50\n","Epoch   4/5 Batch  120/781 - Loss:  1.487, Seconds: 67.00\n","Epoch   4/5 Batch  140/781 - Loss:  1.408, Seconds: 67.80\n","Epoch   4/5 Batch  160/781 - Loss:  1.437, Seconds: 77.63\n","Epoch   4/5 Batch  180/781 - Loss:  1.508, Seconds: 72.59\n","Epoch   4/5 Batch  200/781 - Loss:  1.577, Seconds: 63.13\n","Epoch   4/5 Batch  220/781 - Loss:  1.561, Seconds: 67.92\n","Epoch   4/5 Batch  240/781 - Loss:  1.459, Seconds: 53.03\n","Average loss for this update: 1.546\n","New Record!\n","Epoch   4/5 Batch  260/781 - Loss:  1.377, Seconds: 108.37\n","Epoch   4/5 Batch  280/781 - Loss:  1.254, Seconds: 78.43\n","Epoch   4/5 Batch  300/781 - Loss:  1.385, Seconds: 68.86\n","Epoch   4/5 Batch  320/781 - Loss:  1.441, Seconds: 69.00\n","Epoch   4/5 Batch  340/781 - Loss:  1.667, Seconds: 59.81\n","Epoch   4/5 Batch  360/781 - Loss:  1.519, Seconds: 78.74\n","Epoch   4/5 Batch  380/781 - Loss:  1.473, Seconds: 79.68\n","Epoch   4/5 Batch  400/781 - Loss:  1.342, Seconds: 79.78\n","Epoch   4/5 Batch  420/781 - Loss:  1.292, Seconds: 64.59\n","Epoch   4/5 Batch  440/781 - Loss:  1.336, Seconds: 68.82\n","Epoch   4/5 Batch  460/781 - Loss:  1.488, Seconds: 69.77\n","Epoch   4/5 Batch  480/781 - Loss:  1.551, Seconds: 64.41\n","Epoch   4/5 Batch  500/781 - Loss:  1.432, Seconds: 78.92\n","Average loss for this update: 1.434\n","New Record!\n","Epoch   4/5 Batch  520/781 - Loss:  1.462, Seconds: 76.95\n","Epoch   4/5 Batch  540/781 - Loss:  1.288, Seconds: 61.25\n","Epoch   4/5 Batch  560/781 - Loss:  1.319, Seconds: 67.77\n","Epoch   4/5 Batch  580/781 - Loss:  1.385, Seconds: 66.29\n","Epoch   4/5 Batch  600/781 - Loss:  1.445, Seconds: 61.37\n","Epoch   4/5 Batch  620/781 - Loss:  1.645, Seconds: 77.74\n","Epoch   4/5 Batch  640/781 - Loss:  1.475, Seconds: 81.80\n","Epoch   4/5 Batch  660/781 - Loss:  1.455, Seconds: 72.27\n","Epoch   4/5 Batch  680/781 - Loss:  1.291, Seconds: 65.95\n","Epoch   4/5 Batch  700/781 - Loss:  1.309, Seconds: 79.99\n","Epoch   4/5 Batch  720/781 - Loss:  1.367, Seconds: 72.82\n","Epoch   4/5 Batch  740/781 - Loss:  1.688, Seconds: 57.07\n","Epoch   4/5 Batch  760/781 - Loss:  1.639, Seconds: 61.67\n","Average loss for this update: 1.442\n","No Improvement.\n","Epoch   4/5 Batch  780/781 - Loss:  1.451, Seconds: 71.19\n","Epoch   5/5 Batch   20/781 - Loss:  1.685, Seconds: 74.44\n","Epoch   5/5 Batch   40/781 - Loss:  1.517, Seconds: 75.71\n","Epoch   5/5 Batch   60/781 - Loss:  1.487, Seconds: 65.40\n","Epoch   5/5 Batch   80/781 - Loss:  1.427, Seconds: 81.25\n","Epoch   5/5 Batch  100/781 - Loss:  1.462, Seconds: 70.39\n","Epoch   5/5 Batch  120/781 - Loss:  1.363, Seconds: 70.97\n","Epoch   5/5 Batch  140/781 - Loss:  1.278, Seconds: 71.38\n","Epoch   5/5 Batch  160/781 - Loss:  1.326, Seconds: 82.52\n","Epoch   5/5 Batch  180/781 - Loss:  1.381, Seconds: 75.99\n","Epoch   5/5 Batch  200/781 - Loss:  1.452, Seconds: 66.38\n","Epoch   5/5 Batch  220/781 - Loss:  1.424, Seconds: 71.11\n","Epoch   5/5 Batch  240/781 - Loss:  1.348, Seconds: 54.62\n","Average loss for this update: 1.417\n","New Record!\n","Epoch   5/5 Batch  260/781 - Loss:  1.261, Seconds: 175.85\n","Epoch   5/5 Batch  280/781 - Loss:  1.163, Seconds: 78.07\n","Epoch   5/5 Batch  300/781 - Loss:  1.286, Seconds: 69.46\n","Epoch   5/5 Batch  320/781 - Loss:  1.322, Seconds: 69.42\n","Epoch   5/5 Batch  340/781 - Loss:  1.537, Seconds: 57.90\n","Epoch   5/5 Batch  360/781 - Loss:  1.430, Seconds: 79.04\n","Epoch   5/5 Batch  380/781 - Loss:  1.391, Seconds: 80.02\n","Epoch   5/5 Batch  400/781 - Loss:  1.262, Seconds: 78.58\n","Epoch   5/5 Batch  420/781 - Loss:  1.214, Seconds: 63.68\n","Epoch   5/5 Batch  440/781 - Loss:  1.248, Seconds: 80.35\n","Epoch   5/5 Batch  460/781 - Loss:  1.376, Seconds: 68.99\n","Epoch   5/5 Batch  480/781 - Loss:  1.443, Seconds: 63.88\n","Epoch   5/5 Batch  500/781 - Loss:  1.343, Seconds: 79.06\n","Average loss for this update: 1.337\n","New Record!\n","Epoch   5/5 Batch  520/781 - Loss:  1.380, Seconds: 76.12\n","Epoch   5/5 Batch  540/781 - Loss:  1.210, Seconds: 62.24\n","Epoch   5/5 Batch  560/781 - Loss:  1.228, Seconds: 64.67\n","Epoch   5/5 Batch  580/781 - Loss:  1.292, Seconds: 65.13\n","Epoch   5/5 Batch  600/781 - Loss:  1.345, Seconds: 60.25\n","Epoch   5/5 Batch  620/781 - Loss:  1.539, Seconds: 75.63\n","Epoch   5/5 Batch  640/781 - Loss:  1.366, Seconds: 79.82\n","Epoch   5/5 Batch  660/781 - Loss:  1.367, Seconds: 72.79\n","Epoch   5/5 Batch  680/781 - Loss:  1.191, Seconds: 65.35\n","Epoch   5/5 Batch  700/781 - Loss:  1.211, Seconds: 81.65\n","Epoch   5/5 Batch  720/781 - Loss:  1.278, Seconds: 72.01\n","Epoch   5/5 Batch  740/781 - Loss:  1.566, Seconds: 55.40\n","Epoch   5/5 Batch  760/781 - Loss:  1.533, Seconds: 60.47\n","Average loss for this update: 1.343\n","No Improvement.\n","Epoch   5/5 Batch  780/781 - Loss:  1.350, Seconds: 70.08\n"]}],"source":["# Train the Model\n","learning_rate_decay = 0.95\n","min_learning_rate = 0.0005\n","display_step = 20 # Check training loss after every 20 batches\n","stop_early = 0 \n","stop = 3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n","per_epoch = 3 # Make 3 update checks per epoch\n","update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1\n","\n","update_loss = 0 \n","batch_loss = 0\n","summary_update_loss = [] # Record the update losses for saving improvements in the model\n","\n","checkpoint = \"best_model.ckpt\" \n","with tf.Session(graph=train_graph) as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    # If we want to continue training a previous session\n","    #loader = tf.train.import_meta_graph(\"./\" + checkpoint + '.meta')\n","    #loader.restore(sess, checkpoint)\n","    \n","    for epoch_i in range(1, epochs+1):\n","        update_loss = 0\n","        batch_loss = 0\n","        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n","                get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):\n","            start_time = time.time()\n","            _, loss = sess.run(\n","                [train_op, cost],\n","                {input_data: texts_batch,\n","                 targets: summaries_batch,\n","                 lr: learning_rate,\n","                 summary_length: summaries_lengths,\n","                 text_length: texts_lengths,\n","                 keep_prob: keep_probability})\n","\n","            batch_loss += loss\n","            update_loss += loss\n","            end_time = time.time()\n","            batch_time = end_time - start_time\n","\n","            if batch_i % display_step == 0 and batch_i > 0:\n","                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n","                      .format(epoch_i,\n","                              epochs, \n","                              batch_i, \n","                              len(sorted_texts_short) // batch_size, \n","                              batch_loss / display_step, \n","                              batch_time*display_step))\n","                batch_loss = 0\n","\n","            if batch_i % update_check == 0 and batch_i > 0:\n","                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n","                summary_update_loss.append(update_loss)\n","                \n","                # If the update loss is at a new minimum, save the model\n","                if update_loss <= min(summary_update_loss):\n","                    print('New Record!') \n","                    stop_early = 0\n","                    saver = tf.train.Saver() \n","                    saver.save(sess, checkpoint)\n","\n","                else:\n","                    print(\"No Improvement.\")\n","                    stop_early += 1\n","                    if stop_early == stop:\n","                        break\n","                update_loss = 0\n","            \n","                    \n","        # Reduce learning rate, but not below its minimum value\n","        learning_rate *= learning_rate_decay\n","        if learning_rate < min_learning_rate:\n","            learning_rate = min_learning_rate\n","        \n","        if stop_early == stop:\n","            print(\"Stopping Training.\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vqdixx5baDkh"},"outputs":[],"source":["def text_to_seq(text):\n","    '''Prepare the text for the model'''\n","    \n","    text = clean_text(text)\n","    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSIlKV5A0mP0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669660703632,"user_tz":-330,"elapsed":16157,"user":{"displayName":"DL PROJECT","userId":"10242363612563406762"}},"outputId":"536b0190-f669-4498-cd46-baf998dd2f0f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"]},{"output_type":"stream","name":"stdout","text":["Original Text: cat critically high protein levels kidneys prompting vet put strict kidney protection program since animal organ transplant operations done couldnt let suffer <br ><br >luckily food actually eats best works kidney enzimes back normal range thanks strictly keeping diet unfortunately price food outrageous 40 7lb bag c mon rediculous <br ><br >i stuck since cannot food without deadly consequences cable phone cell movies nothing afford food yes work god get real price people would google places sellers ripping\n","\n","Text\n","  Word Ids:    [233, 34199, 396, 1068, 6290, 19867, 38910, 3932, 1959, 13070, 8708, 11420, 8666, 565, 8789, 21144, 16857, 30872, 2871, 5275, 4313, 6707, 23415, 23416, 24587, 3, 1305, 1090, 25, 469, 8708, 59591, 115, 1693, 2950, 443, 1055, 1725, 34, 3308, 71, 3, 1394, 6536, 31908, 158, 731, 7488, 9009, 23415, 23416, 23424, 4812, 565, 365, 3, 476, 2988, 22456, 22498, 16167, 9915, 3751, 172, 2508, 3, 509, 505, 617, 406, 375, 71, 1127, 93, 2853, 2460, 1608, 6592]\n","  Input Words: cat critically high protein levels kidneys prompting vet put strict kidney protection program since animal organ transplant operations done couldnt let suffer <br ><br >luckily food actually eats best works kidney <UNK> back normal range thanks strictly keeping diet unfortunately price food outrageous 40 7lb bag c mon rediculous <br ><br >i stuck since cannot food without deadly consequences cable phone cell movies nothing afford food yes work god get real price people would google places sellers ripping\n","\n","Summary\n","  Word Ids:       [25, 4384, 70, 17, 424]\n","  Response Words: best tonic for the money\n"]}],"source":["# Create your own review or use one from the dataset\n","#input_sentence = \"I have never eaten an apple before, but this red one was nice. \\\n","                  #I think that I will try a green apple next time.\"\n","#text = text_to_seq(input_sentence)\n","random = np.random.randint(0,len(clean_texts))\n","input_sentence = clean_texts[random]\n","text = text_to_seq(clean_texts[random])\n","\n","checkpoint = \"./best_model.ckpt\"\n","\n","loaded_graph = tf.Graph()\n","with tf.Session(graph=loaded_graph) as sess:\n","    # Load saved model\n","    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n","    loader.restore(sess, checkpoint)\n","\n","    input_data = loaded_graph.get_tensor_by_name('input:0')\n","    logits = loaded_graph.get_tensor_by_name('predictions:0')\n","    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n","    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n","    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n","    \n","    #Multiply by batch_size to match the model's input parameters\n","    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n","                                      summary_length: [np.random.randint(5,8)], \n","                                      text_length: [len(text)]*batch_size,\n","                                      keep_prob: 1.0})[0] \n","\n","# Remove the padding from the tweet\n","pad = vocab_to_int[\"<PAD>\"] \n","\n","print('Original Text:', input_sentence)\n","\n","print('\\nText')\n","print('  Word Ids:    {}'.format([i for i in text]))\n","print('  Input Words: {}'.format(\" \".join([int_to_vocab[i] for i in text])))\n","\n","print('\\nSummary')\n","print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n","print('  Response Words: {}'.format(\" \".join([int_to_vocab[i] for i in answer_logits if i != pad])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeUDsr3H-Esq"},"outputs":[],"source":["INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n","Original Text: love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets\n","\n","Text\n","  Word Ids:    [70595, 18808, 668, 45565, 51927, 51759, 32488, 13510, 32036, 59599, 11693, 444, 23335, 32036, 59599, 51927, 67316, 726, 24842, 50494, 48492, 1062, 44749, 38443, 42344, 67973, 14168, 7759, 5347, 29528, 58763, 18927, 17701, 20232, 47328]\n","  Input Words: love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets\n","\n","Summary\n","  Word Ids:       [70595, 28738]\n","  Response Words: love it\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojnL6l39hgCt"},"outputs":[],"source":["Output of reviews and summaries:\n","Review(1): The coffee tasted great and was at such a good price! I highly recommend this to everyone!\n","Summary(1): great coffee\n","Review(2): This is the worst cheese that I have ever bought! I will never buy it again and I hope you won't either!\n","Summary(2): omg gross gross\n","Review(3): love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets\n","Summary(3): love it"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}